{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI算法工程师\n",
    "## 毕业项目开题报告\n",
    "\n",
    "沈捷 2019年3月28日\n",
    "\n",
    "### 背景\n",
    "\n",
    "2013年，kaggle举办了一项趣味性赛事“猫狗大战”，即猫狗图像分类。许多学者及行业人士参与其中，供献了大量的解决方案，机器学习领域的局势由之改变。<cite data-cite=\"undefined\"></cite>现今图像分类在许多行业已展开深入研究，如医学上热门的癌组织与良性组织的鉴别，甚至有学者尝试利用深度学习方法鉴别出男女大脑MRI图像的差异<cite data-cite=\"2636952/IJ2W7TIB\"></cite>，都是类似的问题。但医学领域常由于患者隐私保护政策，难以获得大量的训练数据，所以为了更好地学习、研究新的方法，也有学者会利用猫狗大战数据进行探索尝试和验证<cite data-cite=\"2636952/YVAJHILJ\"></cite>，同理可以延伸至许多应用领域。\n",
    "\n",
    "### 问题描述\n",
    "\n",
    "区分图片是猫还是狗的照片，显然是一个二分类问题，通过输入图像特征，获得一个概率，通过概率来判断属于哪一个类。\n",
    "\n",
    "### 数据输入\n",
    "\n",
    "该数据集已切分为训练集和测试集。训练集包含25000张图片，猫和狗图片比例为1:1，可以从文件名（*标签.编号.jpg*）中获得标签；测试集有12500张图片，文件名只有编号。\n",
    "\n",
    "随机抽取样本，简单探查这些图片：\n",
    "\n",
    "![samples](samples.jpg)\n",
    "\n",
    "可见图片长或宽多在300~500像素之间，大小不一。背景也各种各样，也许会造成一定程度的干扰，不过目标主体基本清晰居中。只不过有的主体占图片的比例较小，有的图片上有两个或以上的目标，也可能会影响模型训练，且尚不知是否有分类错误的训练样本。\n",
    "\n",
    "对于错误分类样本的检测，决定采用预训练的ResNet50模型进行初始预测，根据ImageNet1000的标签，其中有118个狗的品种和7个猫的品种，可以做为参考，找到那些预测与标签不符的图片，再做人工确认。如下为ResNet50模型中找到的部分错误标签的图：\n",
    "\n",
    "![miss_labeled](ex_files_resnet50_top60_sample.jpg)\n",
    "\n",
    "可见，这些图中有的目标主体太小，有些有遮挡，有些模糊，有些曝光度太高以至特征消失，甚至一张图片上同时有猫和狗或两者都不是，这都是对模型训练的干扰，这部分图片将剔除。\n",
    "\n",
    "其余训练集图片会经过随机旋转、缩放、裁剪等预处理，使模型能有更好的泛化能力。这些图像将统一为$224 \\times 224$大小，并分解为RGB三个颜色通道的色值，作为模型的输入。\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "处理好输入数据后，将采用一个预训练的神经网络进行迁移学习，预计将采用ResNet50模型。该模型要求输入为(224, 224, 3)的tensor，所以图片也会随之调整，同时神经网络的输入节点也应为$224 \\times 224$大小，输出节点数量为1，采用sigmoid激活函数将图像对某一类的线性预测值映射到$(0,1)$之间，即为概率（狗=1，猫=0）。sigmoid函数公式：\n",
    "\n",
    "$$S(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "最后将模型在测试集上进行预测，提交到kaggle上进行比较判断。模型的训练目标即是达到kaggle的前10%。\n",
    "\n",
    "训练模型的过程中，将调整epoch、隐藏层节点、学习速率等超参数，以尽量高准确率，降低对数损失（log loss）。\n",
    "\n",
    "### 基准模型\n",
    "\n",
    "此处将采用vgg16模型做为基准模型，进行迁移学习。vgg16是用ImageNet的图像进行预训练的深度卷积网络模型，具有16个权重层<cite data-cite=\"2636952/UPQRGRJI\"></cite>，可以迁移到未见过的图像进行训练，大大提高训练模型的效率。\n",
    "\n",
    "### 评估指标\n",
    "\n",
    "模型将采用对数损失函数（log loss）进行评价。<cite data-cite=\"2636952/55RLJIS4\"></cite>对数损失函数需要输入每个分类的预测概率与标签，对错误的分类进行惩罚，从而对准确率（Accuracy）进行量化<cite data-cite=\"2636952/K3687SF8\"></cite>。损失越少，准确率越高。对数损失函数公式<cite data-cite=\"2636952/55RLJIS4\"></cite>：\n",
    "\n",
    "$$LogLoss = -\\frac{1}{n}\\sum_{i=1}^{n}[y_{i}log(\\hat{y_i})+(1-y_i)log(1-\\hat{y_i})]$$\n",
    "\n",
    "其中：\n",
    "* n是样本数量\n",
    "* $\\hat{y_i}$是图像$i$为狗的预测概率值\n",
    "* $y_i$是图像$i$的标签，$y_i=1$是狗，$y_i=0$是猫\n",
    "* $log()$是以自然数$e$为底的对数函数\n",
    "\n",
    "此外，预测结果将上传到_Kaggle_进行排名对比，目标是要达到_Kaggle_排名的前10%，即LogLoss达到0.05603。\n",
    "\n",
    "### 项目设计\n",
    "\n",
    "综上，本项目是一个图像的二分类问题。对于训练集图像，首先要进行随机翻转、缩放、裁剪等预处理，并统一成$224 \\times 224$大小，再转化为RGB三个通道的Tensor，与预训练模型的标准化参数进行匹配，作为模型的输入。将采用Pytorch的vgg16为预训练模型框架进行迁移学习，用Sigmoid函数输出图像的预测概率（狗=1，猫=0）。在训练过程中，将调整epoch、隐藏层数、隐藏节点数、学习速率等超参数，尽量提高准确率，降低对数损失。在测试集上进行预测之后，提交到_kaggle_上进行评价对比。_kaggle_则采用对数损失函数(log loss）进行模型准确率的评价。本模型的目标是达到_Kaggle_排名的前10%。\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2636952/55RLJIS4": {
     "URL": "https://kaggle.com/c/dogs-vs-cats-redux-kernels-edition",
     "abstract": "Distinguish images of dogs from cats",
     "accessed": {
      "day": 5,
      "month": 4,
      "year": 2019
     },
     "id": "2636952/55RLJIS4",
     "shortTitle": "Dogs vs. Cats Redux",
     "title": "Dogs vs. Cats Redux: Kernels Edition",
     "title-short": "Dogs vs. Cats Redux",
     "type": "webpage"
    },
    "2636952/IJ2W7TIB": {
     "DOI": "10.3389/fnins.2019.00185",
     "abstract": "Do men and women have different brains? Previous neuroimage studies sought to answer this question based on morphological difference between specific brain regions, reporting unfortunately conflicting results. In the present study, we aim to use a deep learning technique to address this challenge based on a large open-access, diffusion MRI database recorded from 1,065 young healthy subjects, including 490 men and 575 women healthy subjects. Different from commonly used 2D Convolutional Neural Network (CNN), we proposed a 3D CNN method with a newly designed structure including three hidden layers in cascade with a linear layer and a terminal Softmax layer. The proposed 3D CNN was applied to the maps of factional anisotropy (FA) in the whole-brain as well as specific brain regions. The entropy measure was applied to the lowest-level image features extracted from the first hidden layer to examine the difference of brain structure complexity between men and women. The obtained results compared with the results from using the Support Vector Machine (SVM) and Tract-Based Spatial Statistics (TBSS). The proposed 3D CNN yielded a better classification result (93.3%) than the SVM (78.2%) on the whole-brain FA images, indicating gender-related differences likely exist in the whole-brain range. Moreover, high classification accuracies are also shown in several specific brain regions including the left precuneus, the left postcentral gyrus, the left cingulate gyrus, the right orbital gyrus of frontal lobe, and the left occipital thalamus in the gray matter, and middle cerebellum peduncle, genu of corpus callosum, the right anterior corona radiata, the right superior corona radiata and the left anterior limb of internal capsule in the while matter. This study provides a new insight into the structure difference between men and women, which highlights the importance of considering sex as a biological variable in brain research.",
     "author": [
      {
       "family": "Xin",
       "given": "Jiang"
      },
      {
       "family": "Zhang",
       "given": "Yaoxue"
      },
      {
       "family": "Tang",
       "given": "Yan"
      },
      {
       "family": "Yang",
       "given": "Yuan"
      }
     ],
     "container-title": "Frontiers in Neuroscience",
     "container-title-short": "Front Neurosci",
     "id": "2636952/IJ2W7TIB",
     "issued": {
      "year": 2019
     },
     "journalAbbreviation": "Front Neurosci",
     "language": "eng",
     "note": "PMID: 30906246\nPMCID: PMC6418873",
     "page": "185",
     "page-first": "185",
     "shortTitle": "Brain Differences Between Men and Women",
     "title": "Brain Differences Between Men and Women: Evidence From Deep Learning",
     "title-short": "Brain Differences Between Men and Women",
     "type": "article-journal",
     "volume": "13"
    },
    "2636952/K3687SF8": {
     "URL": "https://www.cnblogs.com/klchang/p/9217551.html",
     "abstract": "原理 对数损失, 即对数似然损失(Log-likelihood Loss), 也称逻辑斯谛回归损失(Logistic Loss)或交叉熵损失(cross-entropy Loss), 是在概率估计上定",
     "accessed": {
      "day": 5,
      "month": 4,
      "year": 2019
     },
     "id": "2636952/K3687SF8",
     "language": "zh-cn",
     "title": "对数损失函数(Logarithmic Loss Function)的原理和 Python 实现 - klchang - 博客园",
     "type": "webpage"
    },
    "2636952/UPQRGRJI": {
     "URL": "http://arxiv.org/abs/1409.1556",
     "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
     "accessed": {
      "day": 4,
      "month": 4,
      "year": 2019
     },
     "author": [
      {
       "family": "Simonyan",
       "given": "Karen"
      },
      {
       "family": "Zisserman",
       "given": "Andrew"
      }
     ],
     "container-title": "arXiv:1409.1556 [cs]",
     "id": "2636952/UPQRGRJI",
     "issued": {
      "day": 4,
      "month": 9,
      "year": 2014
     },
     "note": "arXiv: 1409.1556",
     "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
     "type": "article-journal"
    },
    "2636952/YVAJHILJ": {
     "URL": "https://arxiv.org/abs/1712.04621v1",
     "abstract": "In this paper, we explore and compare multiple solutions to the problem of\ndata augmentation in image classification. Previous work has demonstrated the\neffectiveness of data augmentation through simple techniques, such as cropping,\nrotating, and flipping input images. We artificially constrain our access to\ndata to a small subset of the ImageNet dataset, and compare each data\naugmentation technique in turn. One of the more successful data augmentations\nstrategies is the traditional transformations mentioned above. We also\nexperiment with GANs to generate images of different styles. Finally, we\npropose a method to allow a neural net to learn augmentations that best improve\nthe classifier, which we call neural augmentation. We discuss the successes and\nshortcomings of this method on various datasets.",
     "accessed": {
      "day": 29,
      "month": 3,
      "year": 2019
     },
     "author": [
      {
       "family": "Perez",
       "given": "Luis"
      },
      {
       "family": "Wang",
       "given": "Jason"
      }
     ],
     "id": "2636952/YVAJHILJ",
     "issued": {
      "day": 13,
      "month": 12,
      "year": 2017
     },
     "language": "en",
     "title": "The Effectiveness of Data Augmentation in Image Classification using Deep Learning",
     "type": "article-journal"
    },
    "undefined": {
     "URL": "https://kaggle.com/c/dogs-vs-cats-redux-kernels-edition",
     "abstract": "Distinguish images of dogs from cats",
     "accessed": {
      "day": 5,
      "month": 4,
      "year": 2019
     },
     "id": "undefined",
     "shortTitle": "Dogs vs. Cats Redux",
     "title": "Dogs vs. Cats Redux: Kernels Edition",
     "title-short": "Dogs vs. Cats Redux",
     "type": "webpage"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
