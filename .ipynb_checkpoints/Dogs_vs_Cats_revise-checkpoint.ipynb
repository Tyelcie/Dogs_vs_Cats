{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet152\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten,Input, concatenate\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend, layers, models,utils\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras_efficientnets.efficientnet import EfficientNetB3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ex_files.txt', 'rb') as ef:\n",
    "    ex_files = pickle.load(ef)\n",
    "len(ex_files['resnet50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './{}/'\n",
    "files = {x: os.listdir(data_dir.format(x)) for x in ['train', 'test']}\n",
    "clean_data = [i for i in files['train'] if i not in ex_files['resnet50']]\n",
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_labels = [x.split('.')[0] for x in clean_data]\n",
    "df_smpl = pd.DataFrame({i: clean_labels.count(i) for i in set(clean_labels)}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df_smpl, labels = df_smpl.columns, startangle=90, autopct = '%3.1f%%');\n",
    "plt.title('Sample size distribution', fontsize = 20)\n",
    "plt.savefig('sample_size_distribution_train.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './train/'\n",
    "nb_class = 2\n",
    "with open('data_set.txt', 'rb') as ds:\n",
    "    data_set = pickle.load(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.DataFrame({'file_names': clean_data, 'labels': [x.split('.')[0] for x in clean_data]})\n",
    "file_train, file_valid, label_train, label_valid = train_test_split(file_df['file_names'], file_df['labels'],\n",
    "                                                                    test_size = 0.2, random_state = 0)\n",
    "file_valid = file_valid.tolist()\n",
    "file_train = file_train.tolist()\n",
    "print(len(file_train), len(file_valid), len(label_train), len(label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = {'file_train': file_train, 'label_train': label_train, 'file_valid': file_valid, 'label_valid': label_valid}\n",
    "with open('data_set.txt', 'wb') as ds:\n",
    "    pickle.dump(data_set, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查两个数据集有没有重叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20, 6])\n",
    "plt.subplot(1, 2, 1)\n",
    "train_dist = pd.DataFrame(Counter(label_train), index=[0])\n",
    "ax, ltext, ptext = plt.pie(train_dist, labels = train_dist.columns, startangle=90, autopct = '%3.1f%%');\n",
    "plt.title('Sample size distribution of training set', fontsize = 20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "valid_dist = pd.DataFrame(Counter(label_valid), index=[0])\n",
    "plt.pie(valid_dist, labels = valid_dist.columns, startangle=90, autopct = '%3.1f%%')\n",
    "plt.title('Sample size distribution of validation set', fontsize = 20);\n",
    "\n",
    "plt.savefig('sample_size_distribution_train_valid.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(any([data['valid']['cat'][x] in data['train']['cat'] for x in range(len(data['valid']['cat']))]))\n",
    "# print(any([data['valid']['dog'][x] in data['train']['dog'] for x in range(len(data['valid']['dog']))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = {x: pd.DataFrame({'X': data_set['file_{}'.format(x)],\n",
    "                          'Y'.format(x): data_set['label_{}'.format(x)]}) for x in ['train', 'valid']}\n",
    "dataf['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "datagen = {'train': image.ImageDataGenerator(\n",
    "   preprocessing_function=preprocess_input,\n",
    "#     rotation_range=20\n",
    "#     ,width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "#     ,vertical_flip=True\n",
    "),\n",
    "           'valid':image.ImageDataGenerator(\n",
    "   preprocessing_function=preprocess_input\n",
    ")\n",
    "          }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者简单写法便于一个个增删："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = {x: image.ImageDataGenerator(preprocessing_function=preprocess_input) for x in dataf.keys()}\n",
    "datagen['train'].horizontal_flip = True\n",
    "datagen['train'].rotation_range = 30\n",
    "# datagen['train'].zoom_range = [0.2, 0.2]\n",
    "datagen['train'].vertical_flip = True\n",
    "# datagen['train'].zoom_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width, im_height = 224, 224\n",
    "batch_size = 128\n",
    "\n",
    "generator = {x: datagen[x].flow_from_dataframe(\n",
    "    dataf[x], x_col = 'X', y_col = 'Y',directory = data_dir.format('train'),\n",
    "    target_size=(im_width, im_height),\n",
    "    batch_size=batch_size,\n",
    "    seed = 123,\n",
    "    class_mode = 'binary'\n",
    ") for x in datagen.keys()}\n",
    "\n",
    "generator['valid'].shuffle = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择三个模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'VGG19': VGG19, 'ResNet152': ResNet152, 'EfficientNetB3': EfficientNetB3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_name = 'ResNet152'\n",
    "model_base = ResNet152(weights = 'imagenet', include_top = False, input_shape = (im_width, im_height, 3),\n",
    "                           backend = backend, layers = layers, models = models, utils = utils)\n",
    "model_1 = Sequential()\n",
    "model_1.add(model_base)\n",
    "model_1.add(GlobalAveragePooling2D())\n",
    "model_1.add(Dropout(0.75))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "out_1 = model_1.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_name = 'EfficientNetB3'\n",
    "model_base = model_base = model_dict[model_2_name](weights='imagenet', include_top=False, input_shape = (im_width, im_height, 3))\n",
    "model_2 = Sequential()\n",
    "model_2.add(model_base)\n",
    "model_2.add(GlobalAveragePooling2D())\n",
    "model_2.add(Dropout(0.9))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "out_2 = model_2.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_name = 'VGG19'\n",
    "model_base = model_dict[model_3_name](weights='imagenet', include_top=False, input_shape = (im_width, im_height, 3))\n",
    "model_3 = Sequential()\n",
    "model_3.add(model_base)\n",
    "model_3.add(GlobalAveragePooling2D())\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(500, activation = 'relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "out_3 = model_3.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph() \n",
    "if model_name == 'ResNet152':\n",
    "    model_base = ResNet152(weights = 'imagenet', include_top = False, input_shape = (im_width, im_height, 3),\n",
    "                           backend = backend, layers = layers, models = models, utils = utils)\n",
    "else:\n",
    "    model_base = model_dict[model_name](weights='imagenet', include_top=False, input_shape = (im_width, im_height, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 融合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger = concatenate([out_1, out_2])\n",
    "# out = Dense(1, activation='sigmoid')(merger)\n",
    "# model = Model(Input(shape = (im_width, im_height, 3)), out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加自己的层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(model_base)\n",
    "# model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.75))\n",
    "# model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者这种写法：\n",
    "```python\n",
    "x = model_base.output\n",
    "# x = Flatten()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5,)(x)\n",
    "# x = Dense(500, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=model_base.input, outputs=output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看冻结层前后的可训练层数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_2\n",
    "print('Number of trainable weights befor freezing the model_base:', len(model.trainable_weights))\n",
    "# for layer in model.layers[:173]:\n",
    "#     layer.trainable = False\n",
    "model_base.trainable = False\n",
    "print('Number of trainable weights after freezing the model_base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编译模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=lr), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "history = model.fit_generator(generator['train'],\n",
    "                              steps_per_epoch=math.ceil(generator['train'].samples / batch_size),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=generator['valid'],\n",
    "                              validation_steps=math.ceil(generator['valid'].samples / batch_size),\n",
    "                              callbacks=[early_stopping],\n",
    "                              verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型checkpoint："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重新载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the details form the history object\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "x_axis = range(1, len(acc)+1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "\n",
    "plt.figure(figsize = [15, 7])\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x_axis, acc, 'blue', label='Training Accurarcy')\n",
    "plt.plot(x_axis, val_acc, 'red', label='Validation Accurarcy')\n",
    "plt.title('Training and Validation Accurarcy', fontsize = 16)\n",
    "plt.xlabel('Epoches', fontsize = 16)\n",
    "plt.ylabel('Accuracy', fontsize = 16)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.xticks(ticks=range(0, len(acc)+1, 2),fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "#Train and validation loss\n",
    "plt.plot(x_axis, loss, 'blue', label='Training Loss')\n",
    "plt.plot(x_axis, val_loss, 'red', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss', fontsize = 16)\n",
    "plt.xlabel('Epoches', fontsize = 16)\n",
    "plt.ylabel('Loss (Binary cross entropy)', fontsize = 16)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.xticks(ticks=range(0, len(acc)+1, 2), fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "# plt.suptitle('Pre-trained model: {}\\nLearning rate: {}'.format(model_name, lr),\n",
    "#             x = 0.1, y = 1, ha = 'left', fontsize = 14)\n",
    "plt.savefig('{} loss and acc-lr {}.jpg'.format(model_name, lr), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_imgs = os.listdir(data_dir.format('test'))\n",
    "img_path = data_dir.format('test') + test_imgs[3]\n",
    "# img_path = './test04.jpg'\n",
    "img = image.load_img(img_path, target_size=(im_width, im_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)[0][0]\n",
    "print(preds)\n",
    "img_show = mpimg.imread(img_path)\n",
    "plt.imshow(img_show)\n",
    "plt.suptitle('This is a {}'.format('dog' if preds > 0.5 else 'cat'))\n",
    "plt.title('probability: {}%'.format(round(preds*100, 2)) if preds > 0.5 else round((1-preds)*100, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部预测，制作csv表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = os.listdir('test/')\n",
    "ids = []\n",
    "label = []\n",
    "for i in tqdm(test_imgs):\n",
    "    img = image.load_img('test/' + i, target_size=(im_width, im_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    label.append(model.predict(x)[0][0])\n",
    "    ids.append(int(i.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id': ids, 'label': label}).sort_values('id',axis = 0, ascending = True)\n",
    "sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "+ https://zhuanlan.zhihu.com/p/26693647\n",
    "+ https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "+ https://www.kaggle.com/risingdeveloper/transfer-learning-in-keras-on-dogs-vs-cats"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2636952/5RAUEJIJ": {
     "URL": "https://zhuanlan.zhihu.com/p/26693647",
     "abstract": "上图，是CompCars数据集的示例图像，整个数据集包含163家汽车制造商，1713种车型。该怎样训练一个神经网络来区分这些车呢？这里就用到了迁移学习和微调。@王小新 编译自 Deep Learning Sandbox 量子位 出品 | 公众…",
     "accessed": {
      "date-parts": [
       [
        2019,
        4,
        25
       ]
      ]
     },
     "container-title": "知乎专栏",
     "language": "zh",
     "title": "在Keras+TF环境中，用迁移学习和微调打造专属图像识别系统",
     "type": "webpage"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
