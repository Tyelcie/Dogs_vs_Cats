{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂时参考以下博文为蓝本：https://zhuanlan.zhihu.com/p/26693647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = {'train': image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "),\n",
    "           'valid':image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "batch_size = 64\n",
    "generator = {}\n",
    "for i in datagen.keys():\n",
    "    generator[i] = datagen[i].flow_from_directory(\n",
    "        data_dir.format(i),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) \n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) \n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(new_model, model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        new_model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_finetune(new_model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top \n",
    "      layers.\n",
    "    note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in \n",
    "         the inceptionv3 architecture\n",
    "    Args:\n",
    "     model: keras model\n",
    "    \"\"\"\n",
    "    for layer in new_model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "        for layer in new_model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "            layer.trainable = True\n",
    "            new_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                          loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "  generator['train'],\n",
    "  samples_per_epoch=nb_train_samples,\n",
    "  nb_epoch=nb_epoch,\n",
    "  validation_data=generator['valid'],\n",
    "  nb_val_samples=nb_val_samples,\n",
    "  class_weight='auto')\n",
    "\n",
    "model.save(args.output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
