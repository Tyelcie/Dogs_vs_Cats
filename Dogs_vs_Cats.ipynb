{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# from keras_applications.resnet import ResNet152\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend, layers, models,utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './{}/'\n",
    "nb_class = len(os.listdir(data_dir.format('train')))\n",
    "data = {}\n",
    "for i in ['train', 'valid']:\n",
    "    data[i] = {x: os.listdir(data_dir.format(i)+x) for x in os.listdir(data_dir.format(i))}\n",
    "nb_train_samples = sum([len(data['train'][x]) for x in data['train'].keys()])\n",
    "nb_valid_samples = sum([len(data['valid'][x]) for x in data['train'].keys()])\n",
    "nb_test_samples = len(os.listdir(data_dir.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(any([data['valid']['cat'][x] in data['train']['cat'] for x in range(len(data['valid']['cat']))]))\n",
    "print(any([data['valid']['dog'][x] in data['train']['dog'] for x in range(len(data['valid']['dog']))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂时参考以下博文为蓝本：https://zhuanlan.zhihu.com/p/26693647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = {'train': image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True\n",
    "),\n",
    "           'valid':image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    "),\n",
    "           'test': image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用了`preprocess_input()`就不需要`rescale`参数了。\n",
    "\n",
    "https://stackoverflow.com/questions/47555829/preprocess-input-method-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19896 images belonging to 2 classes.\n",
      "Found 4974 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "im_width, im_height = 224, 224\n",
    "# im_width, im_height = 299, 299\n",
    "batch_size = 64\n",
    "seed = 123\n",
    "\n",
    "# generator = {x: datagen[x].flow_from_directory(\n",
    "#     data_dir.format(x),\n",
    "#     target_size=(im_width, im_height),\n",
    "#     batch_size=batch_size,\n",
    "#     seed = 123,\n",
    "#     class_mode = 'binary',\n",
    "#     shuffle = True\n",
    "# ) for x in list(datagen.keys())[:2]}\n",
    "\n",
    "generator = {}\n",
    "\n",
    "generator['train'] = datagen['train'].flow_from_directory(data_dir.format('train'),\n",
    "                                                          target_size=(im_width, im_height),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          seed = seed,\n",
    "                                                          class_mode = 'binary',\n",
    "                                                          shuffle = True)\n",
    "generator['valid'] = datagen['valid'].flow_from_directory(data_dir.format('valid'),\n",
    "                                                          target_size=(im_width, im_height),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          seed = seed,\n",
    "                                                          class_mode = 'binary',\n",
    "                                                          shuffle = True)\n",
    "generator['test'] = datagen['test'].flow_from_directory(data_dir.format('test'),\n",
    "                                                          target_size=(im_width, im_height),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          seed = seed,\n",
    "                                                          class_mode = 'binary',\n",
    "                                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入模型并排除顶部的全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_base = ResNet50(weights='imagenet', include_top=False, input_shape = (im_width, im_height, 3))\n",
    "# model_base = ResNet152(include_top = False, weights = 'imagenet', backend = backend, layers = layers, models = models, utils = utils,\n",
    "#                        input_shape = (im_width, im_height, 3))\n",
    "# model_base = Xception(weights='imagenet', include_top=False, input_shape = (im_width, im_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加自己的层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(model_base)\n",
    "# model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.75))\n",
    "# model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看冻结层前后的可训练层数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable weights befor freezing the model_base: 214\n",
      "Number of trainable weights after freezing the model_base: 2\n"
     ]
    }
   ],
   "source": [
    "print('Number of trainable weights befor freezing the model_base:', len(model.trainable_weights))\n",
    "model_base.trainable = False\n",
    "print('Number of trainable weights after freezing the model_base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编译模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.0005\n",
    "# from keras.utils import multi_gpu_model\n",
    "# model = multi_gpu_model(model_base, gpus=8)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "311/311 [==============================] - 225s 725ms/step - loss: 0.1032 - acc: 0.9605 - val_loss: 0.0548 - val_acc: 0.9805\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 225s 725ms/step - loss: 0.0962 - acc: 0.9620 - val_loss: 0.0531 - val_acc: 0.9799\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 226s 725ms/step - loss: 0.0927 - acc: 0.9642 - val_loss: 0.0573 - val_acc: 0.9799\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 226s 726ms/step - loss: 0.0942 - acc: 0.9652 - val_loss: 0.0487 - val_acc: 0.9817\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 225s 725ms/step - loss: 0.0936 - acc: 0.9639 - val_loss: 0.0466 - val_acc: 0.9821\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 226s 725ms/step - loss: 0.0934 - acc: 0.9654 - val_loss: 0.0455 - val_acc: 0.9823\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 225s 725ms/step - loss: 0.0911 - acc: 0.9658 - val_loss: 0.0461 - val_acc: 0.9823\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 225s 725ms/step - loss: 0.0900 - acc: 0.9675 - val_loss: 0.0490 - val_acc: 0.9807\n",
      "Epoch 9/10\n",
      " 83/311 [=======>......................] - ETA: 2:08 - loss: 0.0882 - acc: 0.9637"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit_generator(generator['train'],\n",
    "                              steps_per_epoch=math.ceil(nb_train_samples / batch_size),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=generator['valid'],\n",
    "                              validation_steps=math.ceil(nb_valid_samples / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型checkpoint："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_binary_wieghts.h5')\n",
    "model.save('model_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the details form the history object\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.figure(figsize = [15, 7])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss and acc.jpg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_imgs = os.listdir(data_dir.format('test'))\n",
    "# img_path = data_dir.format('test') + test_imgs[3]\n",
    "# # img_path = './test04.jpg'\n",
    "# img = image.load_img(img_path, target_size=(im_width, im_height))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)[0][0]\n",
    "# print(preds)\n",
    "# img_show = mpimg.imread(img_path)\n",
    "# plt.imshow(img_show)\n",
    "# plt.title('This is a {}'.format('dog' if preds > 0.5 else 'cat'))\n",
    "# plt.suptitle('probability: {} percent'.format(round(preds, 3)*100) if preds > 0.5 else round(1-preds, 3)*100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部预测，制作csv表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = os.listdir(data_dir.format('test'))\n",
    "ids = []\n",
    "label = []\n",
    "for i in tqdm(test_imgs):\n",
    "    img = image.load_img(data_dir.format('test') + i, target_size=(im_width, im_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    label.append(model.predict(x)[0][0])\n",
    "    ids.append(int(i.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'id': ids, 'label': label}).sort_values('id',axis = 0, ascending = True)\n",
    "sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(generator['test'],\n",
    "                        steps=math.ceil(nb_test_samples / batch_size),\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "+ https://zhuanlan.zhihu.com/p/26693647\n",
    "+ https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "+ https://www.kaggle.com/risingdeveloper/transfer-learning-in-keras-on-dogs-vs-cats"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "2636952/5RAUEJIJ": {
     "URL": "https://zhuanlan.zhihu.com/p/26693647",
     "abstract": "上图，是CompCars数据集的示例图像，整个数据集包含163家汽车制造商，1713种车型。该怎样训练一个神经网络来区分这些车呢？这里就用到了迁移学习和微调。@王小新 编译自 Deep Learning Sandbox 量子位 出品 | 公众…",
     "accessed": {
      "date-parts": [
       [
        2019,
        4,
        25
       ]
      ]
     },
     "container-title": "知乎专栏",
     "language": "zh",
     "title": "在Keras+TF环境中，用迁移学习和微调打造专属图像识别系统",
     "type": "webpage"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
